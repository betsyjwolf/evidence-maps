# Systematic Differences in Intervention Effect Sizes by Outcome Measure Type
This repository provides open access to data analyzed in the paper, "Making sense of effect sizes: Systematic differences in intervention effect sizes by outcome measure type" (under review).

## Abstract

One challenge in understanding “what works” in education is that effect sizes may not be comparable across studies, which presents a problem for practitioners and policymakers who are trying to use research to select educational interventions. One factor that consistently relates to the magnitude of effect sizes is the type of outcome measure. This paper uses study data from the What Works Clearinghouse to examine differences in average effect sizes by outcome measure type. Using advanced meta-analysis and controlling for study quality and implementation, average effect sizes identified on researcher and developer measures are substantially larger than those identified on independent measures not related to the study authors or intervention developers. This study Results call into question conventional theories about why effect sizes are larger on researcher and developer measures. The study concludes that outcome measure type cannot be ignored in making sense about education interventions.

## Graph

If a picture says a thousand words, this is the take-home graph:

## Data

The open access dataset can be found below:

- [Data]


## License to Use These Data

This work was commissioned by the WWC to both inform and promote discussion about the WWC’s research standards. This work was created as part of the Contributor’s official duties as an Employee of the United States Government and is therefore a work of the U.S. Government. The content of the publication does not necessarily reflect the views or policies of the U.S. Government nor does mention of trade names, commercial products, or organizations imply endorsement by the U.S. Government. In accordance with 17 U.S.C. 105, the report and the accompanying data are in the public domain. While permission to use these data is not necessary, the data should be cited as:

Wolf, R., & Harbatkin, E. (under review). Making sense of effect sizes: Systematic differences in intervention effect sizes by outcome measure type. 

## Authors

Wolf is a Research Scientist at the [What Works Clearinghouse](https://ies.ed.gov/ncee/wwc/).
Harbatkin is a Postdoctoral Research Fellow at [Michigan State University](https://education.msu.edu/people/harbatkin-erica/).
Both authors have cats.

## Programs and Packages Used in this Project

* Coburn, K., & Vevea, J. (2019). weightr: Estimating weight-function models for publication bias. R package version 2.0.2. Retrieved from https://CRAN.R-project.org/package=weightr
* Pustejovsky, J. (2019). clubSandwich: Cluster-Robust (Sandwich) Variance Estimators with Small-Sample Corrections. R package version 0.3.5. Retrieved from https://CRAN.R-project.org/package=clubSandwich  Small-Sample Corrections. R package version 0.3.5.
  https://CRAN.R-project.org/package=clubSandwich
* R Core Team (2018). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/. 
* StataCorp. 2019. Stata Statistical Software: Release 16. College Station, TX: StataCorp LLC.
* Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. Journal of
  Statistical Software, 36(3), 1-48. URL: http://www.jstatsoft.org/v36/i03/
 * Wickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag, New York. 
  






